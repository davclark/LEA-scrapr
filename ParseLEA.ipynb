{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from os import path\n",
    "from glob import glob\n",
    "\n",
    "from lxml import etree\n",
    "from lxml.cssselect import CSSSelector as CSS  # also needs cssselect installed\n",
    "from six import print_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Sadly, the pages use CSS or something to make the checkboxes. So, when you look at the bare file, the checked boxes look like this: â˜‘ (unchecked look like â˜). This is likely because Chrome saves files at utf-8 by default, but then renders them as iso-latin or something dumb like that. Thanks Chrome!\n",
    "\n",
    "If you look at the source in a text editor, though, you can see the checkboxes fine.\n",
    "\n",
    "Also, the HTML structure borders on malicious. There is no useful structure (likely HTML was largely driven by layout concerns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melva Davis Academy of Excellence.html\r\n"
     ]
    }
   ],
   "source": [
    "%ls scraped-pages/Adelanto\\ Elementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = './scraped-pages/Adelanto Elementary/Melva Davis Academy of Excellence.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LEA_parser:\n",
    "    # I'm trying to use CSS selectors where possible, as more folks will know these\n",
    "    lists_loc = CSS('ol.zeroindent li')\n",
    "    parse_utf8 = etree.HTMLParser(encoding='utf-8')\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.parsed = etree.parse(filename, self.parse_utf8)\n",
    "        self.extract_responses()\n",
    "\n",
    "        \n",
    "    def extract_responses(self):\n",
    "        curr_items = self.lists_loc(self.parsed)\n",
    "    \n",
    "        self.res = []\n",
    "    \n",
    "        for item in curr_items:\n",
    "            # CSS won't let us grab stuff based on content, only structure\n",
    "            # So, we're using Xpath (and we're using unicode because of how Chrome saved these)\n",
    "            checkboxes = item.xpath('.//span[text()=\"☑\"]')\n",
    "            if not checkboxes:\n",
    "                # string() exports the text of children also... not sure why, \n",
    "                # but text() doesn't work here\n",
    "                if item.xpath('.//*[contains(string(), \"No response\")]'):\n",
    "                    self.res.append('No response')\n",
    "                else:\n",
    "                    self.res.append('Something is amiss with the parser:' + item.xpath('string()'))\n",
    "            else:\n",
    "                # Some sections are multiple choice!\n",
    "                checked_vals = '; '.join(self.get_box_label(box) for box in checkboxes)\n",
    "                self.res.append(checked_vals)\n",
    "\n",
    "                \n",
    "    def get_box_label(self, box_el):\n",
    "        '''Get the label to the right of the checkbox\n",
    "\n",
    "        Currently, this doesn't handle \"(please specify)\" information'''\n",
    "        return box_el.getnext().xpath('string()')\n",
    "    \n",
    "    def as_list(self):\n",
    "        return self.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Awareness',\n",
       " 'The LEA CCSS plan is currently in development.',\n",
       " 'No response',\n",
       " '0-10 hours',\n",
       " '0-10 hours',\n",
       " 'Using formative practices in instruction',\n",
       " 'Activities provided by other vendors; Activities using online professional learning modules from the CDE',\n",
       " 'Conference attendance',\n",
       " 'The LEA does not offer pre-kindergarten or transitional kindergarten programs',\n",
       " 'The LEA does not offer extended learning/after school programs',\n",
       " 'No response',\n",
       " 'Materials are being used in every classroom',\n",
       " 'State Board of Education-adopted materials for mathematics; Teacher-developed materials; Free supplemental materials provided by the publishers of your currently adopted programs; Free supplemental materials provided by a publisher not directly affiliated with your currently adopted programs',\n",
       " 'No response',\n",
       " '0-10 hours',\n",
       " '0-25 percent',\n",
       " 'Yes',\n",
       " 'No response',\n",
       " 'We have not yet presented information regarding CCSS implementation to the governing board',\n",
       " 'We have not yet shared information with parents',\n",
       " 'Newsletters',\n",
       " 'We have not yet engaged in CCSS-related discussions with our local institutions of higher education',\n",
       " 'We have not yet engaged in CCSS-related discussions with our local businesses',\n",
       " 'No response',\n",
       " 'No response']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seems to be working!\n",
    "LEA_parser(fname).as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('parsed_LEA.csv', 'w') as outfile:\n",
    "    outfile = csv.writer(outfile)\n",
    "    # range is up to, but not including the upper limit\n",
    "    outfile.writerow(['District', 'School'] + list(range(1, 26)))\n",
    "\n",
    "    for resp_file in glob('scraped-pages/*/*.html'):\n",
    "        if '00-NotSubmitted' in resp_file:\n",
    "            # These don't have any data in them. Just keeping the files\n",
    "            # because why delete anything?\n",
    "            continue\n",
    "\n",
    "        parsed = LEA_parser(resp_file)\n",
    "\n",
    "        # path.split is annoying - it only does one split\n",
    "        path_elts = resp_file.split('/')\n",
    "        district = path_elts[-2]\n",
    "        school, _ = path.splitext(path_elts[-1])\n",
    "        school = school.replace('_', '/')\n",
    "\n",
    "        outfile.writerow([district, school] + parsed.res)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
